# rag.py
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from vector_db import query_document  # VektÃ¶r DB entegrasyonu

# ğŸ“Œ OpenAI Model YapÄ±landÄ±rmasÄ±
OPENAI_MODEL = "gpt-4"
model = ChatOpenAI(model=OPENAI_MODEL)

def retrieve_and_generate(query):
    """
    KullanÄ±cÄ±nÄ±n sorgusuna en uygun belgeleri vektÃ¶r veritabanÄ±ndan Ã§eker
    ve bu belgelerle bir dil modeli (GPT-4) Ã¼zerinden mantÄ±klÄ± bir yanÄ±t oluÅŸturur.
    """
    retrieved_docs = query_document(query, top_k=3)
    if not retrieved_docs or "metadatas" not in retrieved_docs:
        return "âš ï¸ Uygun belge bulunamadÄ±, lÃ¼tfen farklÄ± bir sorgu deneyin."
    
    # metadatas listesinin ilk elemanÄ±ndaki belgelerden 'text' bilgilerini Ã§Ä±karÄ±yoruz.
    docs = retrieved_docs["metadatas"][0]
    texts = [doc.get("text", "") for doc in docs if "text" in doc]
    context = "\n".join(texts) if texts else "Belge bulunamadÄ±."
    
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", "AÅŸaÄŸÄ±daki bilgileri kullanarak mantÄ±klÄ± bir yanÄ±t oluÅŸtur:\n\n{context}"),
        ("user", "{query}")
    ])
    
    try:
        parser = StrOutputParser()
        chain = prompt_template | model | parser
        response = chain.invoke({"context": context, "query": query})
        return response
    except Exception as e:
        return f"âŒ Hata: {str(e)}"

if __name__ == "__main__":
    test_query = "Yapay zeka nedir?"
    print(retrieve_and_generate(test_query))